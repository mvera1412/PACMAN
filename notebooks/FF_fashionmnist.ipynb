{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDfvCKqisxQC"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcM9GW5ls0Tv"
      },
      "source": [
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(train_images, train_labels), (validation_images, validation_labels) = fashion_mnist.load_data()\n",
        "\n",
        "text_labels = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVkZbT3Ks4SR"
      },
      "source": [
        "train_images = train_images/255.0\n",
        "validation_images = validation_images/255.0\n",
        "batchsize = 256\n",
        "num_epochs = 100000\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
        "callbacks_list = [es]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Llxpssm4BK3O"
      },
      "source": [
        "import pandas as pd\n",
        "data = []\n",
        "units = np.exp2(range(3,5)) #2,13\n",
        "for h in units:\n",
        "  for _ in range(20):\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
        "    model.add(tf.keras.layers.Dense(h, activation='relu',kernel_initializer='glorot_normal'))\n",
        "    model.add(tf.keras.layers.Dense(h, activation='relu',kernel_initializer='he_normal'))\n",
        "    model.add(tf.keras.layers.Dense(10, activation='softmax',kernel_initializer='he_normal'))\n",
        "    model.compile(optimizer=tf.keras.optimizers.Nadam(),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "    entrenamiento = model.fit(x=train_images, y=train_labels, batch_size = batchsize, epochs=num_epochs,validation_data=(validation_images,validation_labels),callbacks=callbacks_list,verbose=0)\n",
        "    train_res = model.evaluate(x=train_images, y=train_labels, batch_size =train_images.shape[0],verbose=0)\n",
        "    test_res = model.evaluate(x=validation_images, y=validation_labels, batch_size =validation_images.shape[0],verbose=0)\n",
        "    prediction = model.predict(x=validation_images)\n",
        "    soft_acc = prediction[np.arange(len(prediction)), validation_labels].mean()\n",
        "    pacman_gap = -np.log(soft_acc)-train_res[0]\n",
        "    jensen_gap = test_res[0]+np.log(soft_acc)\n",
        "    data.append({\n",
        "            'Units': h,\n",
        "            'Train Cross Entropy': train_res[0],\n",
        "            'Hard Accuracy':  1-test_res[1],\n",
        "            'Soft Accuracy': 1-soft_acc,\n",
        "            'PACMAN Gap': pacman_gap,\n",
        "            'Jensen Gap': jensen_gap\n",
        "        })\n",
        "  df = pd.DataFrame(data)\n",
        "  print(df[df['Units']==h].mean())\n",
        "  print(df[df['Units']==h].std())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}