{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRHdgN69mOHL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(5,5), padding='same', activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(tf.keras.layers.MaxPool2D(strides=2))\n",
        "model.add(tf.keras.layers.Conv2D(filters=48, kernel_size=(5,5), padding='valid', activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPool2D(strides=2))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(84, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "model.build()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "2kvhXpTxm-Zh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "metadata": {
        "id": "l7gP6hyNnWpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnd_index = np.arange(train_labels.shape[0])\n",
        "np.random.shuffle(rnd_index)\n",
        "n_datasets = 120\n",
        "ni = int(np.shape(train_labels)[0]/n_datasets)\n",
        "train_images = train_images[rnd_index,:,:]\n",
        "train_labels = train_labels[rnd_index]\n",
        "train_images = np.reshape(train_images,(n_datasets,ni,28,28))\n",
        "train_labels = np.reshape(train_labels,(n_datasets,ni))\n",
        "print(ni)"
      ],
      "metadata": {
        "id": "uVirnrFynmH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reinitialize(model):\n",
        "    for l in model.layers:\n",
        "        if hasattr(l,\"kernel_initializer\"):\n",
        "            l.kernel.assign(l.kernel_initializer(tf.shape(l.kernel)))\n",
        "        if hasattr(l,\"bias_initializer\"):\n",
        "            l.bias.assign(l.bias_initializer(tf.shape(l.bias)))\n",
        "        if hasattr(l,\"recurrent_initializer\"):\n",
        "            l.recurrent_kernel.assign(l.recurrent_initializer(tf.shape(l.recurrent_kernel)))"
      ],
      "metadata": {
        "id": "GKgScnH046Wg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100\n",
        "CEs = np.zeros(n_datasets)\n",
        "CEp = np.zeros(n_datasets)\n",
        "Rp_s = np.zeros(n_datasets)\n",
        "Rp_h = np.zeros(n_datasets)\n",
        "Rs_s = np.zeros(n_datasets)\n",
        "Rs_h = np.zeros(n_datasets)\n",
        "model.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'], optimizer=tf.keras.optimizers.Adam(learning_rate=5e-4))\n",
        "for j in range(n_datasets):\n",
        "  reinitialize(model)\n",
        "  h = model.fit(x=train_images[j,:,:,:], y=train_labels[j,:], batch_size = 64, epochs=epochs)\n",
        "\n",
        "  CEs[j],A = model.evaluate(x=train_images[j,:,:,:], y=train_labels[j,:])\n",
        "  Rs_h[j] = 1.0-A\n",
        "  predicciones = model.predict(train_images[j,:,:,:])\n",
        "  lista = [predicciones[k,train_labels[j,k]] for k in range(np.shape(predicciones)[0])]\n",
        "  Rs_s[j] = 1.0-np.mean(np.array(lista))\n",
        "\n",
        "  CEp[j],A = model.evaluate(x=test_images, y=test_labels)\n",
        "  Rp_h[j] = 1.0-A\n",
        "  predicciones = model.predict(test_images)\n",
        "  lista = [predicciones[k,test_labels[k]] for k in range(np.shape(predicciones)[0])]\n",
        "  Rp_s[j] = 1.0-np.mean(np.array(lista))\n",
        "\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "#np.savez('/content/drive/My Drive/rta2712.npz', CEs = CEs, CEp = CEp, Rp_s = Rp_s, Rp_h = Rp_h, Rs_s = Rs_s, Rs_h = Rs_h)\n"
      ],
      "metadata": {
        "id": "_dXtvY8XsU6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "#npzfile = np.load('/content/drive/My Drive/rta2712.npz')\n",
        "#CEs = npzfile[\"CEs\"]\n",
        "#CEp = npzfile[\"CEp\"]\n",
        "#Rp_s = npzfile[\"Rp_s\"]\n",
        "#Rp_h = npzfile[\"Rp_h\"]\n",
        "#Rs_s = npzfile[\"Rs_s\"]\n",
        "#Rs_h = npzfile[\"Rs_h\"]\n",
        "\n",
        "CEtilde = -np.log(1.0-Rp_s)\n",
        "gen = CEtilde-CEs\n",
        "n_datasets = np.shape(CEs)[0]"
      ],
      "metadata": {
        "id": "r8wujGDDRGCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pts=10000\n",
        "tmin=1e-5\n",
        "tmax=1000\n",
        "nmax = 18 # de deltas\n",
        "Cn = np.zeros(pts)\n",
        "cota = np.zeros((pts,nmax))\n",
        "cuantil = np.zeros(nmax)\n",
        "cuantil01 = np.zeros(nmax)\n",
        "for idx, t in enumerate(np.linspace(tmin,tmax,pts)):\n",
        "  Cn[idx]=np.mean(np.exp(t*(CEtilde-CEs)))\n",
        "  for nd in range(1,nmax+1):\n",
        "    delta = nd / n_datasets\n",
        "    cuantil[nd-1] = np.sort(gen)[n_datasets-nd-1]\n",
        "    cota[idx,nd-1] = np.log(Cn[idx]/delta) / t\n",
        "    cuantil01[nd-1] = np.sort(Rp_h-Rs_h)[n_datasets-nd-1]\n"
      ],
      "metadata": {
        "id": "il_LXZSV9TKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "minimo = np.min(cota[:,5])\n",
        "donde = np.argmin(cota[:,5])\n",
        "\n",
        "ejex = np.linspace(tmin,tmax,pts)\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(ejex,cota[:,5],label = r'$\\frac{1}{t}\\;\\log\\;\\frac{C_n(t)}{\\delta}$') #delta=0.05\n",
        "ax.plot([tmin,tmax],[cuantil[5],cuantil[5]], label = r'$(1-\\delta)$-quantile of CE gap',linestyle='dashed')\n",
        "ax.plot([tmin,tmax],[cuantil01[5],cuantil01[5]], label = r'$(1-\\delta)$-quantile of $R_p^\\ast$ gap',linestyle='dotted')\n",
        "plt.plot(ejex[donde], minimo, marker=\"o\", markersize=5, markeredgecolor=\"blue\", markerfacecolor=\"blue\",label = \"Minimum value\")\n",
        "ax.legend()\n",
        "plt.ylim((0,0.8))\n",
        "ax.set_xlabel(\"t\")\n",
        "ax.set_ylabel(\"Generalization gap\")\n",
        "\n",
        "#plt.savefig(\"cnvst.pdf\")\n",
        "#from google.colab import files\n",
        "#files.download('cnvst.pdf')"
      ],
      "metadata": {
        "id": "TKOocYOW_dhY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}